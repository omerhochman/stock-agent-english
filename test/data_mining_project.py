import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import baostock as bs
from datetime import datetime, timedelta
import requests
from bs4 import BeautifulSoup
import jieba
import jieba.analyse
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.svm import SVR, SVC
from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_error, accuracy_score, classification_report
import pymysql
import mplfinance as mpf
import talib
import io
import base64
import os
import json
import re
from wordcloud import WordCloud
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é‡‘èæ•°æ®åˆ†æä¸é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ’¹",
    layout="wide"
)

# ç”»å›¾è®¾ç½®
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False 

# AIæ¨¡å‹APIé…ç½®
LLM_API_CONFIG = {
    "api_key": st.secrets.get("LLM_API_KEY", "sk-4DKrMT5Du1BR6e1eYvru5kjb7u7FBzPR59cVyChZrC7SJZcg"),
    "base_url": st.secrets.get("LLM_API_BASE_URL", "https://yunwu.ai/v1"),
    "model_name": st.secrets.get("LLM_MODEL_NAME", "gpt-4o"),
    "timeout": 30
}

# é…ç½®MySQLæ•°æ®åº“è¿æ¥
DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': '123456',
    'db': 'financial_analysis',
    'charset': 'utf8mb4'
}

# åˆ›å»ºæ•°æ®åº“è¿æ¥
def create_connection():
    try:
        conn = pymysql.connect(
            host=DB_CONFIG['host'],
            user=DB_CONFIG['user'],
            password=DB_CONFIG['password'],
            db=DB_CONFIG['db'],
            charset='utf8mb4',
            use_unicode=True
        )
        return conn
    except Exception as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None
        
# åˆå§‹åŒ–æ•°æ®åº“
def init_database():
    try:
        conn = pymysql.connect(
            host=DB_CONFIG['host'],
            user=DB_CONFIG['user'],
            password=DB_CONFIG['password'],
            charset=DB_CONFIG['charset']
        )
        cursor = conn.cursor()
        
        # åˆ›å»ºæ•°æ®åº“
        cursor.execute("CREATE DATABASE IF NOT EXISTS financial_analysis")
        cursor.execute("USE financial_analysis")
        
        # åˆ›å»ºè‚¡ç¥¨æ•°æ®è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS stock_data (
            id INT AUTO_INCREMENT PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            date DATE NOT NULL,
            open FLOAT,
            high FLOAT,
            low FLOAT,
            close FLOAT,
            volume BIGINT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX (symbol, date)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)
        
        # åˆ›å»ºæ–°é—»æ•°æ®è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS news_data (
            id INT AUTO_INCREMENT PRIMARY KEY,
            title VARCHAR(255) NOT NULL,
            content TEXT,
            source VARCHAR(100),
            date DATE,
            sentiment FLOAT,
            keywords VARCHAR(255),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX (date)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)
        
        # åˆ›å»ºé¢„æµ‹ç»“æœè¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS prediction_results (
            id INT AUTO_INCREMENT PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            model_name VARCHAR(50) NOT NULL,
            prediction_date DATE NOT NULL,
            predicted_value FLOAT,
            actual_value FLOAT,
            accuracy FLOAT,
            model_params TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX (symbol, prediction_date)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)
        
        # åˆ›å»ºæŒ‡æ•°æ•°æ®è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS index_data (
            id INT AUTO_INCREMENT PRIMARY KEY,
            index_code VARCHAR(20) NOT NULL,
            index_name VARCHAR(50) NOT NULL,
            date DATE NOT NULL,
            open FLOAT,
            high FLOAT,
            low FLOAT,
            close FLOAT,
            volume BIGINT,
            amount FLOAT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX (index_code, date)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)
        
        # åˆ›å»ºè´¢åŠ¡æ•°æ®è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS financial_data (
            id INT AUTO_INCREMENT PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            year INT NOT NULL,
            quarter INT NOT NULL,
            report_type VARCHAR(20) NOT NULL,
            report_date DATE NOT NULL,
            data_type VARCHAR(50) NOT NULL,
            data_value FLOAT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX (symbol, year, quarter, report_type)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)
        
        conn.commit()
        cursor.close()
        conn.close()
        
        st.success("æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸï¼")
    except Exception as e:
        st.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

# ä½¿ç”¨é€šç”¨LLM APIè¿›è¡Œæƒ…æ„Ÿåˆ†æ
def analyze_sentiment_with_llm(text):
    """
    ä½¿ç”¨é€šç”¨LLM APIè¿›è¡Œæ–‡æœ¬æƒ…æ„Ÿåˆ†æ
    è¿”å›å€¼èŒƒå›´ä»-1ï¼ˆæè´Ÿé¢ï¼‰åˆ°1ï¼ˆææ­£é¢ï¼‰
    """
    try:
        # æˆªå–æ–‡æœ¬ï¼Œé¿å…è¿‡é•¿
        if len(text) > 1000:
            text = text[:1000]
            
        # APIè¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {LLM_API_CONFIG['api_key']}"
        }
        
        # APIè¯·æ±‚ä½“
        payload = {
            "model": LLM_API_CONFIG["model_name"],
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæƒ…æ„Ÿåˆ†æAIã€‚è¯·åˆ†æä»¥ä¸‹è´¢ç»æ–°é—»çš„æƒ…æ„Ÿå€¾å‘ï¼Œå¯¹äºè‚¡ç¥¨å¸‚åœº/ä¼ä¸šçš„å½±å“è¯„åˆ†ã€‚è¯„åˆ†èŒƒå›´ä»-1ï¼ˆæåº¦è´Ÿé¢ï¼‰åˆ°1ï¼ˆæåº¦æ­£é¢ï¼‰ï¼Œåªéœ€è¿”å›ä¸€ä¸ªæ•°å­—ï¼Œä¸è¦è§£é‡Šã€‚"},
                {"role": "user", "content": f"å¯¹ä»¥ä¸‹è´¢ç»æ–°é—»è¿›è¡Œæƒ…æ„Ÿåˆ†æè¯„åˆ†(-1åˆ°1)ï¼Œä»…è¿”å›æ•°å­—ï¼š\n\n{text}"}
            ],
            "temperature": 0.3
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            f"{LLM_API_CONFIG['base_url']}/chat/completions",
            headers=headers,
            json=payload,
            timeout=LLM_API_CONFIG["timeout"]
        )
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code == 200:
            response_data = response.json()
            sentiment_score = response_data["choices"][0]["message"]["content"].strip()
            
            # ç¡®ä¿ç»“æœæ˜¯æ•°å­—
            try:
                sentiment_score = float(sentiment_score)
                # ç¡®ä¿åœ¨-1åˆ°1èŒƒå›´å†…
                sentiment_score = max(-1, min(1, sentiment_score))
            except ValueError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä»æ–‡æœ¬ä¸­æå–æ•°å­—
                import re
                match = re.search(r'(-?\d+(\.\d+)?)', sentiment_score)
                if match:
                    sentiment_score = float(match.group(1))
                    sentiment_score = max(-1, min(1, sentiment_score))
                else:
                    # é»˜è®¤ä¸ºä¸­æ€§
                    sentiment_score = 0.0
        else:
            st.warning(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œä½¿ç”¨ä¸­æ€§è¯„åˆ†")
            sentiment_score = 0.0
                
        return sentiment_score
        
    except Exception as e:
        st.warning(f"æƒ…æ„Ÿåˆ†æAPIè°ƒç”¨å¤±è´¥: {e}ï¼Œä½¿ç”¨ä¸­æ€§è¯„åˆ†")
        return 0.0  # å‡ºé”™æ—¶è¿”å›ä¸­æ€§è¯„åˆ†

# é€šè¿‡LLM APIè¿›è¡Œæ–°é—»æ‘˜è¦å’Œå…³é”®ä¿¡æ¯æå–
def extract_news_insights_with_llm(news_df):
    """
    ä½¿ç”¨LLM APIå¯¹ä¸€ç»„æ–°é—»è¿›è¡Œæ‘˜è¦åˆ†æ
    è¿”å›å…³é”®è§è§£å’Œå¸‚åœºè¶‹åŠ¿åˆ†æ
    """
    try:
        # é€‰æ‹©æœ€è¿‘çš„10æ¡æ–°é—»æ ‡é¢˜
        recent_news = news_df.sort_values('date', ascending=False).head(10)
        titles = recent_news['title'].tolist()
        
        # æ„å»ºæ–°é—»æ‘˜è¦è¯·æ±‚
        titles_text = "\n".join([f"{i+1}. {title}" for i, title in enumerate(titles)])
        
        # APIè¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {LLM_API_CONFIG['api_key']}"
        }
        
        # APIè¯·æ±‚ä½“
        payload = {
            "model": LLM_API_CONFIG["model_name"],
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹è´¢ç»æ–°é—»æ ‡é¢˜ï¼Œæå–å…³é”®å¸‚åœºè¶‹åŠ¿å’Œè§è§£ã€‚"},
                {"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹è´¢ç»æ–°é—»æ ‡é¢˜ï¼Œè¯†åˆ«ä¸»è¦å¸‚åœºè¶‹åŠ¿ã€æ½œåœ¨æŠ•èµ„æœºä¼šå’Œé£é™©ã€‚æä¾›ç®€æ´çš„åˆ†æï¼ˆ200å­—ä»¥å†…ï¼‰ï¼š\n\n{titles_text}"}
            ],
            "temperature": 0.7
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            f"{LLM_API_CONFIG['base_url']}/chat/completions",
            headers=headers,
            json=payload,
            timeout=LLM_API_CONFIG["timeout"]
        )
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code == 200:
            response_data = response.json()
            return response_data["choices"][0]["message"]["content"].strip()
        else:
            st.warning(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return "æ— æ³•è·å–æ–°é—»åˆ†æç»“æœï¼Œè¯·æ£€æŸ¥APIè¿æ¥ã€‚"
        
    except Exception as e:
        st.warning(f"æ–°é—»åˆ†æAPIè°ƒç”¨å¤±è´¥: {e}")
        return "æ— æ³•è·å–æ–°é—»åˆ†æç»“æœï¼Œè¯·æ£€æŸ¥APIè¿æ¥ã€‚"

# ä½¿ç”¨LLM APIç”Ÿæˆé¢„æµ‹ç»“æœè§£è¯»
def interpret_prediction_with_llm(stock_name, prediction_data, model_name, metrics):
    """
    ä½¿ç”¨LLM APIè§£è¯»é¢„æµ‹ç»“æœ
    ç”Ÿæˆä¸“ä¸šçš„åˆ†ææŠ¥å‘Š
    """
    try:
        # æ ¼å¼åŒ–é¢„æµ‹æ•°æ®
        prediction_text = f"æ¨¡å‹: {model_name}\n"
        prediction_text += f"é¢„æµ‹å‡†ç¡®ç‡/è¯¯å·®: {metrics}\n"
        prediction_text += f"æœ€è¿‘é¢„æµ‹å€¼: {prediction_data[-1]:.4f}\n"
        
        # APIè¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {LLM_API_CONFIG['api_key']}"
        }
        
        # APIè¯·æ±‚ä½“
        payload = {
            "model": LLM_API_CONFIG["model_name"],
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆï¼Œæ“…é•¿è§£è¯»è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ç»“æœã€‚"},
                {"role": "user", "content": f"è¯·è§£è¯»ä»¥ä¸‹{stock_name}è‚¡ç¥¨çš„é¢„æµ‹ç»“æœï¼Œæä¾›ä¸“ä¸šçš„åˆ†æè§è§£å’Œå¯èƒ½çš„æŠ•èµ„å»ºè®®ï¼ˆ200å­—å·¦å³ï¼‰ï¼š\n\n{prediction_text}"}
            ],
            "temperature": 0.7
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            f"{LLM_API_CONFIG['base_url']}/chat/completions",
            headers=headers,
            json=payload,
            timeout=LLM_API_CONFIG["timeout"]
        )
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code == 200:
            response_data = response.json()
            return response_data["choices"][0]["message"]["content"].strip()
        else:
            st.warning(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return "æ— æ³•è·å–é¢„æµ‹åˆ†æç»“æœï¼Œè¯·æ£€æŸ¥APIè¿æ¥ã€‚"
        
    except Exception as e:
        st.warning(f"é¢„æµ‹è§£è¯»APIè°ƒç”¨å¤±è´¥: {e}")
        return "æ— æ³•è·å–é¢„æµ‹åˆ†æç»“æœï¼Œè¯·æ£€æŸ¥APIè¿æ¥ã€‚"

# ä»BaoStockè·å–è‚¡ç¥¨æ•°æ®
def fetch_stock_data(symbol, start_date, end_date):
    """ä»BaoStockè·å–è‚¡ç¥¨æ•°æ®"""
    try:
        # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰æ•°æ®
        conn = create_connection()
        cursor = conn.cursor()
        
        cursor.execute(f"""
        SELECT * FROM stock_data 
        WHERE symbol = '{symbol}' 
        AND date BETWEEN '{start_date}' AND '{end_date}'
        ORDER BY date ASC
        """)
        
        result = cursor.fetchall()
        
        # å¦‚æœæ•°æ®åº“ä¸­å·²æœ‰å®Œæ•´æ•°æ®ï¼Œç›´æ¥è¿”å›
        if len(result) > 0:
            df = pd.DataFrame(result, columns=['id', 'symbol', 'date', 'open', 'high', 'low', 'close', 'volume', 'created_at'])
            df = df.drop(['id', 'created_at'], axis=1)
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
            return df
        
        # ä½¿ç”¨BaoStockè·å–æ•°æ®
        # ç™»å½•BaoStock
        lg = bs.login()
        if lg.error_code != '0':
            st.error(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
            
        # æ„å»ºå®Œæ•´çš„è‚¡ç¥¨ä»£ç 
        if symbol.startswith('6'):
            bs_symbol = f"sh.{symbol}"
        elif symbol.startswith(('0', '3')):
            bs_symbol = f"sz.{symbol}"
        else:
            bs_symbol = symbol
            
        # è·å–è‚¡ç¥¨æ•°æ®
        rs = bs.query_history_k_data_plus(
            bs_symbol,
            "date,open,high,low,close,volume,amount,adjustflag",
            start_date=start_date,
            end_date=end_date,
            frequency="d",
            adjustflag="3"  # å¤æƒç±»å‹ï¼š3-å‰å¤æƒ 2-åå¤æƒ 1-ä¸å¤æƒ
        )
        
        if rs.error_code != '0':
            st.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None
            
        # å¤„ç†æ•°æ®
        data_list = []
        while (rs.next()):
            data_list.append(rs.get_row_data())
            
        # ç™»å‡ºBaoStock
        bs.logout()
        
        if not data_list:
            st.warning(f"æœªæ‰¾åˆ° {symbol} ä» {start_date} åˆ° {end_date} çš„æ•°æ®")
            return None
            
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(data_list, columns=['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'adjustflag'])
        
        # è½¬æ¢æ•°æ®ç±»å‹
        df['date'] = pd.to_datetime(df['date'])
        df['open'] = df['open'].astype(float)
        df['high'] = df['high'].astype(float)
        df['low'] = df['low'].astype(float)
        df['close'] = df['close'].astype(float)
        df['volume'] = df['volume'].astype(float)
        
        # è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•
        df.set_index('date', inplace=True)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        for idx, row in df.iterrows():
            sql = """
            INSERT INTO stock_data (symbol, date, open, high, low, close, volume)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            """
            cursor.execute(sql, (
                symbol,
                idx.strftime('%Y-%m-%d'),
                float(row['open']),
                float(row['high']),
                float(row['low']),
                float(row['close']),
                float(row['volume'])
            ))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return df
    except Exception as e:
        st.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        try:
            bs.logout()  # ç¡®ä¿ç™»å‡ºBaoStock
        except:
            pass
        return None

# è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å‡½æ•°
def get_stock_basic_info(symbol):
    """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    try:
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
        if symbol.startswith('6'):
            bs_symbol = f"sh.{symbol}"
        elif symbol.startswith(('0', '3')):
            bs_symbol = f"sz.{symbol}"
        else:
            bs_symbol = symbol
            
        # ç™»å½•BaoStock
        lg = bs.login()
        if lg.error_code != '0':
            st.error(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
            
        # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        rs = bs.query_stock_basic(code=bs_symbol)
        
        if rs.error_code != '0':
            st.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None
            
        data_list = []
        while (rs.next()):
            data_list.append(rs.get_row_data())
            
        # ç™»å‡ºBaoStock
        bs.logout()
        
        if data_list:
            return data_list[0]
        else:
            return None
    except Exception as e:
        st.error(f"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        try:
            bs.logout()
        except:
            pass
        return None

# è·å–å…¨éƒ¨è‚¡ç¥¨åˆ—è¡¨
def get_stock_list():
    """è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åˆ—è¡¨"""
    try:
        # ç™»å½•BaoStock
        lg = bs.login()
        if lg.error_code != '0':
            st.error(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
            return []
            
        # è·å–Aè‚¡ä»£ç åˆ—è¡¨
        rs = bs.query_stock_basic()
        
        if rs.error_code != '0':
            st.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return []
            
        data_list = []
        while (rs.next()):
            row = rs.get_row_data()
            # åªé€‰å–Aè‚¡ä¸”çŠ¶æ€ä¸ºä¸Šå¸‚çš„è‚¡ç¥¨
            if row[4] == '1' and row[5] == '1':  # type=1è¡¨ç¤ºAè‚¡ï¼Œstatus=1è¡¨ç¤ºä¸Šå¸‚
                data_list.append({'code': row[0], 'name': row[1]})
                
        # ç™»å‡ºBaoStock
        bs.logout()
        
        return data_list
    except Exception as e:
        st.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        try:
            bs.logout()
        except:
            pass
        return []

# è·å–è¡Œä¸šåˆ†ç±»æ•°æ®
def get_industry_data():
    """è·å–è¡Œä¸šåˆ†ç±»æ•°æ®"""
    try:
        # ç™»å½•BaoStock
        lg = bs.login()
        if lg.error_code != '0':
            st.error(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
            
        # è·å–è¡Œä¸šåˆ†ç±»æ•°æ®
        rs = bs.query_stock_industry()
        
        if rs.error_code != '0':
            st.error(f"è·å–è¡Œä¸šåˆ†ç±»å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None
            
        industry_list = []
        while (rs.next()):
            industry_list.append(rs.get_row_data())
            
        # ç™»å‡ºBaoStock
        bs.logout()
        
        if industry_list:
            df = pd.DataFrame(industry_list, columns=[
                'code', 'code_name', 'industry', 'industry_classification'
            ])
            return df
        else:
            return None
    except Exception as e:
        st.error(f"è·å–è¡Œä¸šåˆ†ç±»æ•°æ®å¤±è´¥: {e}")
        try:
            bs.logout()
        except:
            pass
        return None

# è·å–æŒ‡æ•°æ•°æ®
def fetch_index_data(index_code, start_date, end_date):
    """è·å–æŒ‡æ•°æ•°æ®"""
    try:
        # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰æ•°æ®
        conn = create_connection()
        cursor = conn.cursor()
        
        index_name = {
            'sh.000001': 'ä¸Šè¯æŒ‡æ•°',
            'sz.399001': 'æ·±è¯æˆæŒ‡',
            'sz.399006': 'åˆ›ä¸šæ¿æŒ‡',
            'sh.000016': 'ä¸Šè¯50',
            'sh.000300': 'æ²ªæ·±300',
            'sz.399905': 'ä¸­è¯500'
        }.get(index_code, index_code)
        
        cursor.execute(f"""
        SELECT * FROM index_data 
        WHERE index_code = '{index_code}' 
        AND date BETWEEN '{start_date}' AND '{end_date}'
        ORDER BY date ASC
        """)
        
        result = cursor.fetchall()
        
        # å¦‚æœæ•°æ®åº“ä¸­å·²æœ‰å®Œæ•´æ•°æ®ï¼Œç›´æ¥è¿”å›
        if len(result) > 0:
            df = pd.DataFrame(result, columns=['id', 'index_code', 'index_name', 'date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'created_at'])
            df = df.drop(['id', 'index_code', 'index_name', 'created_at'], axis=1)
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
            return df
        
        # ç™»å½•BaoStock
        lg = bs.login()
        if lg.error_code != '0':
            st.error(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
            
        # è·å–æŒ‡æ•°æ•°æ®
        rs = bs.query_history_k_data_plus(
            index_code,
            "date,open,high,low,close,volume,amount",
            start_date=start_date,
            end_date=end_date,
            frequency="d"
        )
        
        if rs.error_code != '0':
            st.error(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None
            
        data_list = []
        while (rs.next()):
            data_list.append(rs.get_row_data())
            
        # ç™»å‡ºBaoStock
        bs.logout()
        
        if not data_list:
            st.warning(f"æœªæ‰¾åˆ°æŒ‡æ•° {index_code} ä» {start_date} åˆ° {end_date} çš„æ•°æ®")
            return None
            
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(data_list, columns=[
            'date', 'open', 'high', 'low', 'close', 'volume', 'amount'
        ])
        
        # è½¬æ¢æ•°æ®ç±»å‹
        df['date'] = pd.to_datetime(df['date'])
        numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            
        # è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•
        df.set_index('date', inplace=True)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        for idx, row in df.iterrows():
            sql = """
            INSERT INTO index_data (index_code, index_name, date, open, high, low, close, volume, amount)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            cursor.execute(sql, (
                index_code,
                index_name,
                idx.strftime('%Y-%m-%d'),
                float(row['open']),
                float(row['high']),
                float(row['low']),
                float(row['close']),
                float(row['volume']),
                float(row['amount'])
            ))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return df
    except Exception as e:
        st.error(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        try:
            bs.logout()
        except:
            pass
        return None

# è·å–äº¤æ˜“æ—¥å†
def get_trade_calendar(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†"""
    try:
        # ç™»å½•BaoStock
        lg = bs.login()
        if lg.error_code != '0':
            st.error(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
            
        # è·å–äº¤æ˜“æ—¥å†
        rs = bs.query_trade_dates(start_date=start_date, end_date=end_date)
        
        if rs.error_code != '0':
            st.error(f"è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None
            
        data_list = []
        while (rs.next()):
            data_list.append(rs.get_row_data())
            
        # ç™»å‡ºBaoStock
        bs.logout()
        
        if data_list:
            df = pd.DataFrame(data_list, columns=['calendar_date', 'is_trading_day'])
            df['calendar_date'] = pd.to_datetime(df['calendar_date'])
            df['is_trading_day'] = df['is_trading_day'].apply(lambda x: True if x == '1' else False)
            return df
        else:
            return None
    except Exception as e:
        st.error(f"è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
        try:
            bs.logout()
        except:
            pass
        return None

# è·å–å…¬å¸è´¢åŠ¡æ•°æ®
def get_financial_data(symbol, year, quarter):
    """è·å–å…¬å¸è´¢åŠ¡æ•°æ®"""
    try:
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
        if symbol.startswith('6'):
            bs_symbol = f"sh.{symbol}"
        elif symbol.startswith(('0', '3')):
            bs_symbol = f"sz.{symbol}"
        else:
            bs_symbol = symbol
            
        # ç™»å½•BaoStock
        lg = bs.login()
        if lg.error_code != '0':
            st.error(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
            
        # è·å–å­£åº¦ä¸šç»©æŠ¥è¡¨
        rs = bs.query_performance_express_report(bs_symbol, year, quarter)
        
        if rs.error_code != '0':
            st.error(f"è·å–å­£åº¦ä¸šç»©æŠ¥è¡¨å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None
            
        data_list = []
        while (rs.next()):
            data_list.append(rs.get_row_data())
            
        # è·å–åˆ©æ¶¦è¡¨
        rs_profit = bs.query_profit_data(bs_symbol, year=year, quarter=quarter)
        
        profit_data = []
        if rs_profit.error_code == '0':
            while (rs_profit.next()):
                profit_data.append(rs_profit.get_row_data())
                
        # è·å–èµ„äº§è´Ÿå€ºè¡¨
        rs_balance = bs.query_balance_data(bs_symbol, year=year, quarter=quarter)
        
        balance_data = []
        if rs_balance.error_code == '0':
            while (rs_balance.next()):
                balance_data.append(rs_balance.get_row_data())
                
        # è·å–ç°é‡‘æµé‡è¡¨
        rs_cash = bs.query_cash_flow_data(bs_symbol, year=year, quarter=quarter)
        
        cash_flow_data = []
        if rs_cash.error_code == '0':
            while (rs_cash.next()):
                cash_flow_data.append(rs_cash.get_row_data())
        
        # ç™»å‡ºBaoStock
        bs.logout()
        
        result = {
            'performance': pd.DataFrame(data_list) if data_list else None,
            'profit': pd.DataFrame(profit_data) if profit_data else None,
            'balance': pd.DataFrame(balance_data) if balance_data else None,
            'cash_flow': pd.DataFrame(cash_flow_data) if cash_flow_data else None
        }
        
        return result
    except Exception as e:
        st.error(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
        try:
            bs.logout()
        except:
            pass
        return None

# çˆ¬å–æ–°é—»æ•°æ®
def fetch_news_data(keyword, num_pages=2):
    """çˆ¬å–æ–°æµªè´¢ç»æ–°é—»æ•°æ®"""
    try:
        all_news = []
        
        for page in range(1, num_pages + 1):
            url = f"https://search.sina.com.cn/?q={keyword}&c=news&from=&col=&range=&source=&country=&size=&time=&a=&page={page}&pf=0&ps=0&dpc=1"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            news_items = soup.select('.box-result')
            
            for item in news_items:
                try:
                    title_elem = item.select_one('h2 a')
                    if not title_elem:
                        continue
                        
                    title = title_elem.text.strip()
                    link = title_elem['href']
                    
                    # æå–æ—¥æœŸ
                    time_elem = item.select_one('.fgray_time')
                    news_date = datetime.now().strftime('%Y-%m-%d')
                    if time_elem:
                        date_str = time_elem.text.strip()
                        if 'å¹´' in date_str and 'æœˆ' in date_str and 'æ—¥' in date_str:
                            date_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', date_str)
                            if date_match:
                                year, month, day = date_match.groups()
                                news_date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                    
                    # è·å–æ–°é—»å†…å®¹
                    content = ""
                    try:
                        news_response = requests.get(link, headers=headers, timeout=5)
                        news_soup = BeautifulSoup(news_response.text, 'html.parser')
                        content_elem = news_soup.select_one('.article-content') or news_soup.select_one('#artibody')
                        if content_elem:
                            paras = content_elem.select('p')
                            content = '\n'.join([p.text.strip() for p in paras])
                    except Exception as e:
                        content = "è·å–å†…å®¹å¤±è´¥"
                    
                    # æå–å…³é”®è¯
                    keywords = jieba.analyse.extract_tags(title + ' ' + content, topK=5, withWeight=False)
                    keywords_str = ','.join(keywords)
                    
                    # è°ƒç”¨å¤§æ¨¡å‹APIè¿›è¡Œæƒ…æ„Ÿåˆ†æ
                    sentiment = analyze_sentiment_with_llm(title + ' ' + content)
                    
                    news_data = {
                        'title': title,
                        'content': content[:500],  # åªä¿å­˜éƒ¨åˆ†å†…å®¹
                        'source': 'sina',
                        'date': news_date,
                        'sentiment': sentiment,
                        'keywords': keywords_str
                    }
                    
                    all_news.append(news_data)
                    
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    conn = create_connection()
                    cursor = conn.cursor()
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    cursor.execute("SELECT id FROM news_data WHERE title = %s", (title,))
                    if cursor.fetchone() is None:
                        sql = """
                        INSERT INTO news_data (title, content, source, date, sentiment, keywords)
                        VALUES (%s, %s, %s, %s, %s, %s)
                        """
                        try:
                            cursor.execute(sql, (
                                title,
                                content[:1000],
                                'sina',
                                news_date,
                                sentiment,
                                keywords_str
                            ))
                            conn.commit()
                        except Exception as e:
                            st.warning(f"ä¿å­˜æ–°é—»æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                    
                    cursor.close()
                    conn.close()
                    
                except Exception as e:
                    st.warning(f"å¤„ç†å•æ¡æ–°é—»æ—¶å‡ºé”™: {e}")
                    continue
        
        return pd.DataFrame(all_news)
    except Exception as e:
        st.error(f"è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

# æ•°æ®å¤„ç†å‡½æ•°
def preprocess_stock_data(df):
    """
    é¢„å¤„ç†è‚¡ç¥¨æ•°æ®ï¼Œè®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
    if df is None or df.empty:
        return None
    
    # å¤åˆ¶ä¸€ä»½æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®
    df_processed = df.copy()
    
    # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
    df_processed['MA5'] = df_processed['close'].rolling(window=5).mean()
    df_processed['MA10'] = df_processed['close'].rolling(window=10).mean()
    df_processed['MA20'] = df_processed['close'].rolling(window=20).mean()
    
    # è®¡ç®—æ”¶ç›Šç‡
    df_processed['Daily_Return'] = df_processed['close'].pct_change()
    
    # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆæ ‡å‡†å·®ï¼‰
    df_processed['Volatility_5d'] = df_processed['Daily_Return'].rolling(window=5).std()
    
    # è®¡ç®—MACD
    close = df_processed['close'].values
    if len(close) > 26:
        df_processed['EMA12'] = talib.EMA(close, timeperiod=12)
        df_processed['EMA26'] = talib.EMA(close, timeperiod=26)
        df_processed['MACD'] = df_processed['EMA12'] - df_processed['EMA26']
        df_processed['Signal'] = talib.EMA(df_processed['MACD'].values, timeperiod=9)
        df_processed['Histogram'] = df_processed['MACD'] - df_processed['Signal']
    
    # è®¡ç®—RSI
    if len(close) > 14:
        df_processed['RSI'] = talib.RSI(close, timeperiod=14)
    
    # å¤„ç†ç¼ºå¤±å€¼
    df_processed.fillna(method='bfill', inplace=True)
    
    # æ·»åŠ è¶‹åŠ¿æ ‡ç­¾ï¼ˆåˆ†ç±»é—®é¢˜ä½¿ç”¨ï¼‰
    df_processed['Target_Classification'] = 0
    df_processed.loc[df_processed['close'].shift(-1) > df_processed['close'], 'Target_Classification'] = 1
    
    # æ·»åŠ æœªæ¥nå¤©ä»·æ ¼å˜åŒ–ï¼ˆå›å½’é—®é¢˜ä½¿ç”¨ï¼‰
    for days in [1, 3, 5]:
        df_processed[f'Target_Regression_{days}d'] = df_processed['close'].shift(-days) / df_processed['close'] - 1
    
    # å†æ¬¡å¤„ç†å¯èƒ½å‡ºç°çš„ç¼ºå¤±å€¼
    df_processed.dropna(inplace=True)
    
    return df_processed

# ç‰¹å¾å·¥ç¨‹å‡½æ•°
def create_features(df, target_col, prediction_days=5):
    """
    åˆ›å»ºç‰¹å¾å’Œç›®æ ‡å˜é‡
    """
    # ç‰¹å¾åˆ—
    feature_columns = ['open', 'high', 'low', 'close', 'volume', 
                        'MA5', 'MA10', 'MA20', 'Daily_Return', 
                        'Volatility_5d']
    
    if 'RSI' in df.columns:
        feature_columns.extend(['RSI'])
        
    if 'MACD' in df.columns:
        feature_columns.extend(['MACD', 'Signal', 'Histogram'])
    
    # æå–ç‰¹å¾å’Œç›®æ ‡
    X = df[feature_columns].values
    y = df[target_col].values
    
    # å½’ä¸€åŒ–ç‰¹å¾
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
    
    return X_train, X_test, y_train, y_test, scaler, feature_columns

# æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå‡½æ•°
def train_model(X_train, y_train, model_name):
    """
    è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹
    """
    if model_name == "linear_regression":
        model = LinearRegression()
    elif model_name == "decision_tree":
        model = DecisionTreeRegressor(max_depth=5, random_state=42)
    elif model_name == "random_forest":
        model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)
    elif model_name == "svm":
        model = SVR(kernel='rbf')
    elif model_name == "decision_tree_classifier":
        model = DecisionTreeClassifier(max_depth=5, random_state=42)
    elif model_name == "random_forest_classifier":
        model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
    elif model_name == "svm_classifier":
        model = SVC(kernel='rbf', probability=True)
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹")
    
    model.fit(X_train, y_train)
    return model

# K-Meansèšç±»å‡½æ•°
def cluster_stocks(df, n_clusters=3):
    """
    ä½¿ç”¨K-Meansèšç±»ç®—æ³•å¯¹è‚¡ç¥¨æ•°æ®è¿›è¡Œèšç±»
    """
    # é€‰æ‹©ç”¨äºèšç±»çš„ç‰¹å¾
    features = ['Daily_Return', 'Volatility_5d']
    if 'RSI' in df.columns:
        features.append('RSI')
    
    # æå–ç‰¹å¾
    X = df[features].dropna().values
    
    # å½’ä¸€åŒ–
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    
    # åº”ç”¨K-Means
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(X_scaled)
    
    # æ·»åŠ èšç±»æ ‡ç­¾åˆ°æ•°æ®æ¡†
    cluster_df = df.copy()
    cluster_df = cluster_df.dropna(subset=features)
    cluster_df['Cluster'] = clusters
    
    return cluster_df, kmeans.cluster_centers_

# å¯è§†åŒ–å‡½æ•°
def plot_stock_price(df):
    """ç»˜åˆ¶è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿å›¾"""
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(df.index, df['close'], label='æ”¶ç›˜ä»·')
    ax.plot(df.index, df['MA5'], label='5æ—¥å‡çº¿')
    ax.plot(df.index, df['MA20'], label='20æ—¥å‡çº¿')
    ax.set_title('è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿å›¾')
    ax.set_xlabel('æ—¥æœŸ')
    ax.set_ylabel('ä»·æ ¼')
    ax.legend()
    ax.grid(True)
    return fig

def plot_candlestick(df):
    """ç»˜åˆ¶Kçº¿å›¾"""
    df_plot = df.copy()
    df_plot.index.name = 'Date'
    
    # é‡å‘½ååˆ—ä»¥åŒ¹é…mplfinanceè¦æ±‚
    df_plot = df_plot.rename(columns={
        'open': 'Open',
        'high': 'High',
        'low': 'Low',
        'close': 'Close',
        'volume': 'Volume'
    })
    
    # ä½¿ç”¨mplfinanceç»˜åˆ¶Kçº¿å›¾
    fig, axlist = mpf.plot(df_plot, type='candle', volume=True, 
                          title='è‚¡ç¥¨Kçº¿å›¾',
                          ylabel='ä»·æ ¼',
                          ylabel_lower='æˆäº¤é‡',
                          style='charles',
                          returnfig=True,
                          figsize=(10, 8))
    
    return fig

def plot_technical_indicators(df):
    """ç»˜åˆ¶æŠ€æœ¯æŒ‡æ ‡"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)
    
    # MACDå›¾
    if 'MACD' in df.columns:
        ax1.plot(df.index, df['MACD'], label='MACD')
        ax1.plot(df.index, df['Signal'], label='Signal')
        ax1.bar(df.index, df['Histogram'], label='Histogram', alpha=0.5)
        ax1.set_title('MACDæŒ‡æ ‡')
        ax1.legend()
        ax1.grid(True)
    
    # RSIå›¾
    if 'RSI' in df.columns:
        ax2.plot(df.index, df['RSI'], color='purple', label='RSI')
        ax2.axhline(y=70, color='r', linestyle='-', alpha=0.3)
        ax2.axhline(y=30, color='g', linestyle='-', alpha=0.3)
        ax2.set_title('RSIæŒ‡æ ‡')
        ax2.set_ylabel('RSI')
        ax2.set_xlabel('æ—¥æœŸ')
        ax2.legend()
        ax2.grid(True)
        
    plt.tight_layout()
    return fig

def plot_prediction_results(y_test, y_pred, model_name):
    """ç»˜åˆ¶é¢„æµ‹ç»“æœå¯¹æ¯”å›¾"""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    ax.plot(y_test, label='å®é™…å€¼')
    ax.plot(y_pred, label='é¢„æµ‹å€¼')
    ax.set_title(f'{model_name} é¢„æµ‹ç»“æœ')
    ax.set_xlabel('æ ·æœ¬')
    ax.set_ylabel('å€¼')
    ax.legend()
    ax.grid(True)
    
    return fig

def plot_correlation_heatmap(df):
    """ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾"""
    # é€‰æ‹©æ•°å€¼åˆ—
    numeric_df = df.select_dtypes(include=[np.number])
    
    # è®¡ç®—ç›¸å…³æ€§
    corr = numeric_df.corr()
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax, fmt=".2f")
    ax.set_title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
    
    return fig

def plot_clusters(df, feature_x, feature_y):
    """ç»˜åˆ¶èšç±»ç»“æœ"""
    if 'Cluster' not in df.columns:
        return None
        
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # ä¸ºæ¯ä¸ªèšç±»ç»˜åˆ¶æ•£ç‚¹å›¾
    clusters = df['Cluster'].unique()
    for cluster in clusters:
        cluster_data = df[df['Cluster'] == cluster]
        ax.scatter(cluster_data[feature_x], cluster_data[feature_y], 
                   label=f'èšç±» {cluster}', alpha=0.7)
    
    ax.set_title('è‚¡ç¥¨èšç±»ç»“æœ')
    ax.set_xlabel(feature_x)
    ax.set_ylabel(feature_y)
    ax.legend()
    ax.grid(True)
    
    return fig

def plot_news_sentiment(news_df):
    """ç»˜åˆ¶æ–°é—»æƒ…æ„Ÿåˆ†æ"""
    if news_df.empty or 'sentiment' not in news_df.columns:
        return None
        
    # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—å¹³å‡æƒ…æ„Ÿå¾—åˆ†
    if 'date' in news_df.columns:
        sentiment_by_date = news_df.groupby('date')['sentiment'].mean().reset_index()
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(sentiment_by_date['date'], sentiment_by_date['sentiment'], color='skyblue')
        ax.set_title('æ¯æ—¥æ–°é—»æƒ…æ„Ÿå¾—åˆ†')
        ax.set_xlabel('æ—¥æœŸ')
        ax.set_ylabel('æƒ…æ„Ÿå¾—åˆ†ï¼ˆè´Ÿé¢â†’æ­£é¢ï¼‰')
        ax.grid(True, axis='y')
        plt.xticks(rotation=45)
        
        return fig
    return None

def generate_news_wordcloud(news_df):
    """ç”Ÿæˆæ–°é—»å…³é”®è¯è¯äº‘"""
    if news_df.empty:
        return None
        
    # æå–æ‰€æœ‰å…³é”®è¯
    all_keywords = []
    if 'keywords' in news_df.columns:
        for keywords in news_df['keywords']:
            if isinstance(keywords, str):
                all_keywords.extend(keywords.split(','))
    
    # å¦‚æœæ²¡æœ‰å…³é”®è¯ï¼Œä½¿ç”¨æ ‡é¢˜
    if not all_keywords and 'title' in news_df.columns:
        text = ' '.join(news_df['title'].dropna().tolist())
        words = jieba.cut(text)
        all_keywords = [w for w in words if len(w) > 1]
    
    if not all_keywords:
        return None
        
    text = ' '.join(all_keywords)
    
    # ç”Ÿæˆè¯äº‘
    wordcloud = WordCloud(width=800, height=400, background_color='white', 
                          font_path='simhei.ttf' if os.path.exists('simhei.ttf') else None,
                          max_words=100).generate(text)
    
    # æ˜¾ç¤ºè¯äº‘
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title('æ–°é—»å…³é”®è¯è¯äº‘')
    
    return fig

# ä¿å­˜ç»“æœå‡½æ•°
def save_prediction_to_db(symbol, model_name, prediction_date, predicted_value, actual_value, accuracy, model_params):
    """å°†é¢„æµ‹ç»“æœä¿å­˜åˆ°æ•°æ®åº“"""
    try:
        conn = create_connection()
        cursor = conn.cursor()
        
        sql = """
        INSERT INTO prediction_results 
        (symbol, model_name, prediction_date, predicted_value, actual_value, accuracy, model_params)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        """
        
        cursor.execute(sql, (
            symbol,
            model_name,
            prediction_date,
            float(predicted_value),
            float(actual_value) if actual_value is not None else None,
            float(accuracy),
            json.dumps(model_params)
        ))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return True
    except Exception as e:
        st.error(f"ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“å¤±è´¥: {e}")
        return False

def get_table_download_link(df, filename, text):
    """ç”Ÿæˆæ•°æ®ä¸‹è½½é“¾æ¥"""
    csv = df.to_csv(index=True)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href

def export_to_excel(df, filename):
    """å¯¼å‡ºæ•°æ®åˆ°Excel"""
    output = io.BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    df.to_excel(writer, sheet_name='Sheet1')
    writer.close()
    output.seek(0)
    
    b64 = base64.b64encode(output.read()).decode()
    href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">{filename}</a>'
    return href

# æ•°æ®è·å–æ ‡ç­¾é¡µ
def data_acquisition_tab():
    st.header("æ•°æ®è·å–")
    
    # åˆ›å»ºä¸¤åˆ—
    col1, col2 = st.columns(2)
    
    # è‚¡ç¥¨æ•°æ®è·å–
    with col1:
        st.subheader("è‚¡ç¥¨æ•°æ®è·å–")
        
        # å¢åŠ è‚¡ç¥¨ä»£ç é€‰é¡¹
        stock_input_type = st.radio(
            "é€‰æ‹©è¾“å…¥æ–¹å¼",
            ["ç›´æ¥è¾“å…¥", "ä»åˆ—è¡¨é€‰æ‹©"],
            horizontal=True
        )
        
        if stock_input_type == "ç›´æ¥è¾“å…¥":
            symbol = st.text_input("è‚¡ç¥¨ä»£ç ", "600000")
            st.caption("Aè‚¡ä»£ç æ ¼å¼: 600000(ä¸Šè¯) æˆ– 000001(æ·±è¯)")
        else:
            try:
                # è·å–Aè‚¡ä»£ç åˆ—è¡¨
                with st.spinner("æ­£åœ¨è·å–è‚¡ç¥¨åˆ—è¡¨..."):
                    stock_list = get_stock_list()
                
                if stock_list:
                    # è½¬æ¢ä¸ºå¯é€‰æ‹©çš„æ ¼å¼
                    stock_options = [f"{stock['code'].split('.')[-1]} - {stock['name']}" for stock in stock_list[:1000]]  # é™åˆ¶æ•°é‡é¿å…è¿‡å¤š
                    selected_stock = st.selectbox("é€‰æ‹©è‚¡ç¥¨", stock_options)
                    symbol = selected_stock.split(' - ')[0]  # æå–è‚¡ç¥¨ä»£ç 
                else:
                    st.error("è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
                    symbol = st.text_input("è‚¡ç¥¨ä»£ç ", "600000")
            except Exception as e:
                st.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
                symbol = st.text_input("è‚¡ç¥¨ä»£ç ", "600000")
        
        start_date = st.date_input("å¼€å§‹æ—¥æœŸ", datetime.now() - timedelta(days=365))
        end_date = st.date_input("ç»“æŸæ—¥æœŸ", datetime.now())
        
        if st.button("è·å–è‚¡ç¥¨æ•°æ®"):
            with st.spinner("æ­£åœ¨è·å–è‚¡ç¥¨æ•°æ®..."):
                # ä¿å­˜è‚¡ç¥¨ä»£ç åˆ°ä¼šè¯çŠ¶æ€
                st.session_state.stock_symbol = symbol
                
                stock_df = fetch_stock_data(symbol, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))
                if stock_df is not None and not stock_df.empty:
                    st.session_state.stock_df = stock_df
                    st.success(f"æˆåŠŸè·å– {symbol} çš„è‚¡ç¥¨æ•°æ®ï¼Œå…± {len(stock_df)} æ¡è®°å½•")
                    st.dataframe(stock_df.head())
                else:
                    st.error("è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥")
                    
        # æ·»åŠ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æŒ‰é’®
        if 'stock_symbol' in st.session_state:
            if st.button("è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"):
                with st.spinner("æ­£åœ¨è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯..."):
                    try:
                        symbol = st.session_state.stock_symbol
                        stock_info = get_stock_basic_info(symbol)
                        
                        if stock_info:
                            st.write("è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯:")
                            st.write(f"è‚¡ç¥¨ä»£ç : {stock_info[0]}")
                            st.write(f"è‚¡ç¥¨åç§°: {stock_info[1]}")
                            st.write(f"ä¸Šå¸‚æ—¥æœŸ: {stock_info[2]}")
                            st.write(f"é€€å¸‚æ—¥æœŸ: {stock_info[3] if stock_info[3] else 'è‡³ä»Š'}")
                            st.write(f"è‚¡ç¥¨ç±»å‹: {'Aè‚¡' if stock_info[4]=='1' else 'å…¶ä»–'}")
                            st.write(f"çŠ¶æ€: {'ä¸Šå¸‚' if stock_info[5]=='1' else 'é€€å¸‚'}")
                        else:
                            st.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {symbol} çš„åŸºæœ¬ä¿¡æ¯")
                    except Exception as e:
                        st.error(f"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        
        # æ·»åŠ è·å–è´¢åŠ¡æ•°æ®æŒ‰é’®
        if 'stock_symbol' in st.session_state:
            st.subheader("è´¢åŠ¡æ•°æ®è·å–")
            
            col_year, col_quarter = st.columns(2)
            with col_year:
                year = st.selectbox("é€‰æ‹©å¹´ä»½", list(range(datetime.now().year, 2005, -1)))
            with col_quarter:
                quarter = st.selectbox("é€‰æ‹©å­£åº¦", [1, 2, 3, 4])
                
            if st.button("è·å–è´¢åŠ¡æ•°æ®"):
                with st.spinner("æ­£åœ¨è·å–è´¢åŠ¡æ•°æ®..."):
                    try:
                        symbol = st.session_state.stock_symbol
                        financial_data = get_financial_data(symbol, year, quarter)
                        
                        if financial_data:
                            # æ˜¾ç¤ºä¸šç»©æŠ¥è¡¨
                            if financial_data['performance'] is not None and not financial_data['performance'].empty:
                                st.write("å­£åº¦ä¸šç»©æŠ¥è¡¨:")
                                st.dataframe(financial_data['performance'])
                                
                            # æ˜¾ç¤ºåˆ©æ¶¦è¡¨æ‘˜è¦
                            if financial_data['profit'] is not None and not financial_data['profit'].empty:
                                st.write("åˆ©æ¶¦è¡¨æ‘˜è¦:")
                                profit_summary = financial_data['profit']
                                # é€‰æ‹©å…³é”®æŒ‡æ ‡æ˜¾ç¤º
                                key_profit_metrics = ['code', 'pubDate', 'statDate', 'roeAvg', 'npMargin', 'gpMargin', 'netProfit', 'epsTTM', 'MBRevenue', 'totalShare']
                                metrics_to_show = [col for col in key_profit_metrics if col in financial_data['profit'].columns]
                                st.dataframe(financial_data['profit'][metrics_to_show])
                                
                                # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                                st.session_state.financial_data = financial_data
                            else:
                                st.warning(f"æœªæ‰¾åˆ° {symbol} {year}å¹´ç¬¬{quarter}å­£åº¦çš„è´¢åŠ¡æ•°æ®")
                        else:
                            st.warning(f"æœªæ‰¾åˆ° {symbol} {year}å¹´ç¬¬{quarter}å­£åº¦çš„è´¢åŠ¡æ•°æ®")
                    except Exception as e:
                        st.error(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
    
    # æŒ‡æ•°æ•°æ®è·å–å’Œæ–°é—»æ•°æ®
    with col2:
        st.subheader("æŒ‡æ•°æ•°æ®è·å–")
        
        # ä¸»è¦æŒ‡æ•°åˆ—è¡¨
        major_indices = {
            'sh.000001': 'ä¸Šè¯æŒ‡æ•°',
            'sz.399001': 'æ·±è¯æˆæŒ‡',
            'sz.399006': 'åˆ›ä¸šæ¿æŒ‡',
            'sh.000016': 'ä¸Šè¯50',
            'sh.000300': 'æ²ªæ·±300',
            'sz.399905': 'ä¸­è¯500'
        }
        
        selected_index = st.selectbox("é€‰æ‹©æŒ‡æ•°", list(major_indices.items()), format_func=lambda x: x[1])
        
        index_start_date = st.date_input("æŒ‡æ•°å¼€å§‹æ—¥æœŸ", datetime.now() - timedelta(days=365), key="index_start")
        index_end_date = st.date_input("æŒ‡æ•°ç»“æŸæ—¥æœŸ", datetime.now(), key="index_end")
        
        if st.button("è·å–æŒ‡æ•°æ•°æ®"):
            with st.spinner("æ­£åœ¨è·å–æŒ‡æ•°æ•°æ®..."):
                index_code = selected_index[0]
                index_df = fetch_index_data(index_code, index_start_date.strftime('%Y-%m-%d'), index_end_date.strftime('%Y-%m-%d'))
                
                if index_df is not None and not index_df.empty:
                    st.session_state.index_df = index_df
                    st.session_state.index_name = selected_index[1]
                    st.success(f"æˆåŠŸè·å– {selected_index[1]} çš„æŒ‡æ•°æ•°æ®ï¼Œå…± {len(index_df)} æ¡è®°å½•")
                    st.dataframe(index_df.head())
                else:
                    st.error("è·å–æŒ‡æ•°æ•°æ®å¤±è´¥")
        
        # æ–°é—»æ•°æ®çˆ¬å–
        st.subheader("æ–°é—»æ•°æ®çˆ¬å–")
        
        news_keyword = st.text_input("æœç´¢å…³é”®è¯", "é˜¿é‡Œå·´å·´")
        news_pages = st.slider("çˆ¬å–é¡µæ•°", 1, 5, 2)
        
        if st.button("è·å–æ–°é—»æ•°æ®"):
            with st.spinner("æ­£åœ¨è·å–æ–°é—»æ•°æ®..."):
                news_df = fetch_news_data(news_keyword, news_pages)
                if not news_df.empty:
                    st.session_state.news_df = news_df
                    st.success(f"æˆåŠŸè·å– {len(news_df)} æ¡æ–°é—»æ•°æ®")
                    st.dataframe(news_df[['title', 'date', 'sentiment']].head())
                else:
                    st.error("è·å–æ–°é—»æ•°æ®å¤±è´¥")
    
    # è¡Œä¸šåˆ†ç±»æ•°æ®
    st.subheader("è¡Œä¸šåˆ†ç±»æ•°æ®")
    
    if st.button("è·å–è¡Œä¸šåˆ†ç±»æ•°æ®"):
        with st.spinner("æ­£åœ¨è·å–è¡Œä¸šåˆ†ç±»æ•°æ®..."):
            industry_df = get_industry_data()
            
            if industry_df is not None and not industry_df.empty:
                st.session_state.industry_df = industry_df
                st.success(f"æˆåŠŸè·å–è¡Œä¸šåˆ†ç±»æ•°æ®ï¼Œå…± {len(industry_df)} æ¡è®°å½•")
                
                # æ˜¾ç¤ºè¡Œä¸šç»Ÿè®¡
                industry_counts = industry_df['industry'].value_counts().reset_index()
                industry_counts.columns = ['è¡Œä¸š', 'ä¸Šå¸‚å…¬å¸æ•°é‡']
                
                # æ˜¾ç¤ºè¡Œä¸šåˆ†å¸ƒå›¾è¡¨
                st.write("è¡Œä¸šåˆ†å¸ƒ:")
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.bar(industry_counts['è¡Œä¸š'][:15], industry_counts['ä¸Šå¸‚å…¬å¸æ•°é‡'][:15])
                ax.set_xlabel('è¡Œä¸š')
                ax.set_ylabel('ä¸Šå¸‚å…¬å¸æ•°é‡')
                ax.set_title('å„è¡Œä¸šä¸Šå¸‚å…¬å¸æ•°é‡(å‰15å)')
                plt.xticks(rotation=45, ha='right')
                plt.tight_layout()
                st.pyplot(fig)
                
                # æ˜¾ç¤ºè¡Œä¸šåˆ†ç±»æ•°æ®è¡¨æ ¼
                st.write("è¡Œä¸šåˆ†ç±»æ•°æ®:")
                st.dataframe(industry_df.head(20))
            else:
                st.error("è·å–è¡Œä¸šåˆ†ç±»æ•°æ®å¤±è´¥")
                
    # äº¤æ˜“æ—¥å†æ•°æ®
    st.subheader("äº¤æ˜“æ—¥å†æ•°æ®")
    
    calendar_col1, calendar_col2 = st.columns(2)
    with calendar_col1:
        calendar_start = st.date_input("æ—¥å†å¼€å§‹æ—¥æœŸ", datetime.now() - timedelta(days=30), key="calendar_start")
    with calendar_col2:
        calendar_end = st.date_input("æ—¥å†ç»“æŸæ—¥æœŸ", datetime.now(), key="calendar_end")
        
    if st.button("è·å–äº¤æ˜“æ—¥å†"):
        with st.spinner("æ­£åœ¨è·å–äº¤æ˜“æ—¥å†..."):
            calendar_df = get_trade_calendar(calendar_start.strftime('%Y-%m-%d'), calendar_end.strftime('%Y-%m-%d'))
            
            if calendar_df is not None and not calendar_df.empty:
                st.session_state.calendar_df = calendar_df
                st.success(f"æˆåŠŸè·å–äº¤æ˜“æ—¥å†ï¼Œå…± {len(calendar_df)} æ¡è®°å½•")
                
                # æ˜¾ç¤ºäº¤æ˜“æ—¥å’Œéäº¤æ˜“æ—¥æ•°é‡
                trading_days = calendar_df[calendar_df['is_trading_day']].shape[0]
                non_trading_days = calendar_df[~calendar_df['is_trading_day']].shape[0]
                
                st.write(f"äº¤æ˜“æ—¥æ•°é‡: {trading_days}")
                st.write(f"éäº¤æ˜“æ—¥æ•°é‡: {non_trading_days}")
                
                # æ˜¾ç¤ºäº¤æ˜“æ—¥å†è¡¨æ ¼
                st.write("äº¤æ˜“æ—¥å†:")
                st.dataframe(calendar_df)
            else:
                st.error("è·å–äº¤æ˜“æ—¥å†å¤±è´¥")
                
    # æ–‡ä»¶ä¸Šä¼ 
    st.subheader("ä¸Šä¼ CSV/Excelæ–‡ä»¶")
    uploaded_file = st.file_uploader("é€‰æ‹©æ–‡ä»¶", type=["csv", "xlsx", "xls"])
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.success(f"æˆåŠŸä¸Šä¼ æ–‡ä»¶ï¼Œå…± {len(df)} æ¡è®°å½•")
            st.dataframe(df.head())
            st.session_state.uploaded_df = df
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºè‚¡ç¥¨æ•°æ®
            if all(col in df.columns for col in ['open', 'high', 'low', 'close']):
                st.info("æ£€æµ‹åˆ°ä¸Šä¼ çš„æ˜¯è‚¡ç¥¨æ•°æ®ï¼Œå¯åœ¨æ•°æ®åˆ†ææ ‡ç­¾é¡µè¿›è¡Œå¤„ç†")
        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")

# æ•°æ®åˆ†ææ ‡ç­¾é¡µ
def data_analysis_tab():
    st.header("æ•°æ®åˆ†æ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è‚¡ç¥¨æ•°æ®
    if 'stock_df' in st.session_state:
        st.subheader("è‚¡ç¥¨æ•°æ®é¢„å¤„ç†")
        
        if st.button("æ•°æ®é¢„å¤„ç†"):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                processed_df = preprocess_stock_data(st.session_state.stock_df)
                if processed_df is not None:
                    st.session_state.processed_df = processed_df
                    st.success("æ•°æ®é¢„å¤„ç†å®Œæˆ")
                    st.write("å¤„ç†åçš„æ•°æ®æ ·æœ¬ï¼š")
                    st.dataframe(processed_df.head())
                    
                    # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
                    st.subheader("åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
                    st.write(processed_df.describe())
                    
                    # æ˜¾ç¤ºæŠ€æœ¯æŒ‡æ ‡
                    st.subheader("æŠ€æœ¯æŒ‡æ ‡")
                    tech_indicators = ['close', 'MA5', 'MA20']
                    if 'RSI' in processed_df.columns:
                        tech_indicators.append('RSI')
                    st.line_chart(processed_df[tech_indicators])
        
        if 'processed_df' in st.session_state:
            # ç›¸å…³æ€§åˆ†æ
            st.subheader("ç›¸å…³æ€§åˆ†æ")
            if st.button("ç”Ÿæˆç›¸å…³æ€§çŸ©é˜µ"):
                # é€‰æ‹©æ•°å€¼åˆ—
                numeric_df = st.session_state.processed_df.select_dtypes(include=[np.number])
                corr = numeric_df.corr()
                
                # æ˜¾ç¤ºç›¸å…³æ€§çŸ©é˜µ
                st.write("ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µï¼š")
                st.dataframe(corr.style.background_gradient(cmap='coolwarm'))
                
                # ç›¸å…³æ€§çƒ­åŠ›å›¾
                fig = plot_correlation_heatmap(st.session_state.processed_df)
                st.pyplot(fig)
                
            # æ·»åŠ æ•°æ®å¯è§†åŒ–é€‰é¡¹
            st.subheader("æ•°æ®å¯è§†åŒ–")
            
            viz_type = st.selectbox(
                "é€‰æ‹©å¯è§†åŒ–ç±»å‹",
                ["Kçº¿å›¾", "æŠ€æœ¯æŒ‡æ ‡", "æ”¶ç›Šç‡åˆ†å¸ƒ"]
            )
            
            if viz_type == "Kçº¿å›¾":
                if st.button("ç”ŸæˆKçº¿å›¾"):
                    fig = plot_candlestick(st.session_state.processed_df)
                    st.pyplot(fig)
            
            elif viz_type == "æŠ€æœ¯æŒ‡æ ‡":
                if st.button("ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡å›¾"):
                    fig = plot_technical_indicators(st.session_state.processed_df)
                    st.pyplot(fig)
            
            elif viz_type == "æ”¶ç›Šç‡åˆ†å¸ƒ":
                if st.button("ç”Ÿæˆæ”¶ç›Šç‡åˆ†å¸ƒå›¾"):
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.hist(st.session_state.processed_df['Daily_Return'].dropna(), bins=50)
                    ax.set_title("æ—¥æ”¶ç›Šç‡åˆ†å¸ƒ")
                    ax.set_xlabel("æ—¥æ”¶ç›Šç‡")
                    ax.set_ylabel("é¢‘ç‡")
                    ax.grid(True)
                    st.pyplot(fig)
    elif 'uploaded_df' in st.session_state:
        if all(col in st.session_state.uploaded_df.columns for col in ['open', 'high', 'low', 'close']):
            st.info("ä½¿ç”¨ä¸Šä¼ çš„è‚¡ç¥¨æ•°æ®")
            if st.button("å¤„ç†ä¸Šä¼ çš„æ•°æ®"):
                with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                    processed_df = preprocess_stock_data(st.session_state.uploaded_df)
                    if processed_df is not None:
                        st.session_state.processed_df = processed_df
                        st.success("æ•°æ®é¢„å¤„ç†å®Œæˆ")
                        st.write("å¤„ç†åçš„æ•°æ®æ ·æœ¬ï¼š")
                        st.dataframe(processed_df.head())
        else:
            st.info("ä¸Šä¼ çš„æ–‡ä»¶ä¸æ˜¯æ ‡å‡†è‚¡ç¥¨æ•°æ®æ ¼å¼ï¼Œè¯·ç¡®ä¿åŒ…å«open, high, low, closeåˆ—")
    else:
        st.info("è¯·å…ˆåœ¨æ•°æ®è·å–æ ‡ç­¾é¡µä¸­è·å–è‚¡ç¥¨æ•°æ®")
    
    # æŒ‡æ•°æ•°æ®åˆ†æ
    if 'index_df' in st.session_state:
        st.subheader("æŒ‡æ•°æ•°æ®åˆ†æ")
        
        if st.button("åˆ†ææŒ‡æ•°æ•°æ®"):
            with st.spinner("æ­£åœ¨åˆ†ææŒ‡æ•°æ•°æ®..."):
                index_df = st.session_state.index_df
                index_name = st.session_state.index_name
                
                # è®¡ç®—æŒ‡æ•°çš„ç§»åŠ¨å¹³å‡çº¿
                index_df['MA5'] = index_df['close'].rolling(window=5).mean()
                index_df['MA20'] = index_df['close'].rolling(window=20).mean()
                index_df['MA60'] = index_df['close'].rolling(window=60).mean()
                
                # è®¡ç®—æŒ‡æ•°çš„æ”¶ç›Šç‡
                index_df['Daily_Return'] = index_df['close'].pct_change()
                
                # æ˜¾ç¤ºæŒ‡æ•°åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
                st.write(f"{index_name}åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ï¼š")
                st.dataframe(index_df.describe())
                
                # ç»˜åˆ¶æŒ‡æ•°èµ°åŠ¿å›¾
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.plot(index_df.index, index_df['close'], label='æ”¶ç›˜ä»·')
                ax.plot(index_df.index, index_df['MA5'], label='5æ—¥å‡çº¿')
                ax.plot(index_df.index, index_df['MA20'], label='20æ—¥å‡çº¿')
                ax.plot(index_df.index, index_df['MA60'], label='60æ—¥å‡çº¿')
                ax.set_title(f'{index_name}èµ°åŠ¿å›¾')
                ax.set_xlabel('æ—¥æœŸ')
                ax.set_ylabel('ä»·æ ¼')
                ax.legend()
                ax.grid(True)
                plt.xticks(rotation=45)
                plt.tight_layout()
                st.pyplot(fig)
                
                # ç»˜åˆ¶æŒ‡æ•°æ”¶ç›Šç‡åˆ†å¸ƒå›¾
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.hist(index_df['Daily_Return'].dropna(), bins=50)
                ax.set_title(f'{index_name}æ—¥æ”¶ç›Šç‡åˆ†å¸ƒ')
                ax.set_xlabel('æ—¥æ”¶ç›Šç‡')
                ax.set_ylabel('é¢‘ç‡')
                ax.grid(True)
                st.pyplot(fig)
                
                # å¦‚æœæœ‰è‚¡ç¥¨æ•°æ®ï¼Œè®¡ç®—ä¸æŒ‡æ•°çš„ç›¸å…³æ€§
                if 'processed_df' in st.session_state:
                    st.subheader("è‚¡ç¥¨ä¸æŒ‡æ•°ç›¸å…³æ€§åˆ†æ")
                    
                    stock_df = st.session_state.processed_df
                    
                    # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸç±»å‹
                    if not isinstance(stock_df.index, pd.DatetimeIndex):
                        stock_df.index = pd.to_datetime(stock_df.index)
                    
                    # è®¡ç®—å…±åŒçš„æ—¥æœŸèŒƒå›´
                    common_dates = sorted(set(stock_df.index) & set(index_df.index))
                    
                    if common_dates:
                        # æå–å…±åŒæ—¥æœŸèŒƒå›´çš„æ•°æ®
                        stock_returns = stock_df.loc[common_dates, 'Daily_Return']
                        index_returns = index_df.loc[common_dates, 'Daily_Return']
                        
                        # è®¡ç®—ç›¸å…³ç³»æ•°
                        correlation = stock_returns.corr(index_returns)
                        
                        st.write(f"è‚¡ç¥¨ä¸{index_name}æ”¶ç›Šç‡ç›¸å…³ç³»æ•°: {correlation:.4f}")
                        
                        # ç»˜åˆ¶æ•£ç‚¹å›¾
                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.scatter(index_returns, stock_returns, alpha=0.5)
                        ax.set_title(f'è‚¡ç¥¨æ”¶ç›Šç‡ vs {index_name}æ”¶ç›Šç‡ (ç›¸å…³ç³»æ•°: {correlation:.4f})')
                        ax.set_xlabel(f'{index_name}æ—¥æ”¶ç›Šç‡')
                        ax.set_ylabel('è‚¡ç¥¨æ—¥æ”¶ç›Šç‡')
                        ax.grid(True)
                        
                        # æ·»åŠ å›å½’çº¿
                        z = np.polyfit(index_returns, stock_returns, 1)
                        p = np.poly1d(z)
                        ax.plot(index_returns, p(index_returns), "r--")
                        
                        st.pyplot(fig)
                        
                        # è®¡ç®—Betaç³»æ•°
                        beta = correlation * (stock_returns.std() / index_returns.std())
                        st.write(f"Betaç³»æ•°ï¼ˆå¸‚åœºæ•æ„Ÿåº¦ï¼‰: {beta:.4f}")
                        st.write(f"Betaè§£é‡Š: {'é«˜äºå¸‚åœºæ³¢åŠ¨æ€§' if beta > 1 else 'ä½äºå¸‚åœºæ³¢åŠ¨æ€§'}")
    
    # æ–°é—»æ•°æ®åˆ†æ
    if 'news_df' in st.session_state:
        st.subheader("æ–°é—»æ•°æ®åˆ†æ")
        
        # æŒ‰æ—¥æœŸèšåˆæ–°é—»
        if 'date' in st.session_state.news_df.columns:
            news_count_by_date = st.session_state.news_df.groupby('date').size().reset_index(name='count')
            st.write("æ¯æ—¥æ–°é—»æ•°é‡ï¼š")
            st.bar_chart(news_count_by_date.set_index('date'))
        
        # æƒ…æ„Ÿåˆ†æ
        if 'sentiment' in st.session_state.news_df.columns:
            st.write("æ–°é—»æƒ…æ„Ÿåˆ†å¸ƒï¼š")
            fig, ax = plt.subplots()
            ax.hist(st.session_state.news_df['sentiment'], bins=20)
            ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ†')
            ax.set_ylabel('é¢‘ç‡')
            ax.set_title('æ–°é—»æƒ…æ„Ÿåˆ†å¸ƒç›´æ–¹å›¾')
            st.pyplot(fig)
            
            # å¹³å‡æƒ…æ„Ÿå¾—åˆ†
            avg_sentiment = st.session_state.news_df['sentiment'].mean()
            st.metric("å¹³å‡æƒ…æ„Ÿå¾—åˆ†", f"{avg_sentiment:.3f}", 
                      delta="ç§¯æ" if avg_sentiment > 0 else "æ¶ˆæ")
            
            # ç”Ÿæˆè¯äº‘
            st.write("æ–°é—»å…³é”®è¯è¯äº‘ï¼š")
            fig = generate_news_wordcloud(st.session_state.news_df)
            if fig:
                st.pyplot(fig)
            
            # ä½¿ç”¨å¤§æ¨¡å‹åˆ†ææ–°é—»æ´å¯Ÿ
            st.subheader("æ–°é—»æ´å¯Ÿåˆ†æ")
            if st.button("åˆ†ææ–°é—»è¶‹åŠ¿"):
                with st.spinner("æ­£åœ¨ä½¿ç”¨AIåˆ†ææ–°é—»è¶‹åŠ¿..."):
                    insights = extract_news_insights_with_llm(st.session_state.news_df)
                    st.info(insights)
                    
                    # ä¿å­˜æ–°é—»æ´å¯Ÿåˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.news_insights = insights
    else:
        st.info("è¯·å…ˆåœ¨æ•°æ®è·å–æ ‡ç­¾é¡µä¸­è·å–æ–°é—»æ•°æ®")
    
    # è¡Œä¸šæ•°æ®åˆ†æ
    if 'industry_df' in st.session_state:
        st.subheader("è¡Œä¸šæ•°æ®åˆ†æ")
        
        industry_df = st.session_state.industry_df
        
        # æ˜¾ç¤ºè¡Œä¸šç»Ÿè®¡
        industry_counts = industry_df['industry'].value_counts()
        
        # é€‰æ‹©ç‰¹å®šè¡Œä¸šåˆ†æ
        selected_industry = st.selectbox(
            "é€‰æ‹©è¦åˆ†æçš„è¡Œä¸š",
            options=sorted(industry_df['industry'].unique())
        )
        
        if st.button("åˆ†æè¡Œä¸šè‚¡ç¥¨"):
            with st.spinner("æ­£åœ¨åˆ†æè¡Œä¸šè‚¡ç¥¨..."):
                # ç­›é€‰æ‰€é€‰è¡Œä¸šçš„è‚¡ç¥¨
                industry_stocks = industry_df[industry_df['industry'] == selected_industry]
                
                st.write(f"{selected_industry}è¡Œä¸šä¸Šå¸‚å…¬å¸: {len(industry_stocks)}å®¶")
                st.dataframe(industry_stocks)
                
                # è‚¡ç¥¨ä»£ç åˆ—è¡¨
                stock_codes = industry_stocks['code'].tolist()
                
                # å¦‚æœæœ‰è‚¡ç¥¨å’ŒæŒ‡æ•°æ•°æ®ï¼Œæ·»åŠ è¡Œä¸šä¸å¸‚åœºå¯¹æ¯”åˆ†æé€‰é¡¹
                if 'processed_df' in st.session_state and 'index_df' in st.session_state:
                    st.subheader("è¡Œä¸šä¸ä¸ªè‚¡ã€å¤§ç›˜å¯¹æ¯”")
                    
                    stock_symbol = st.session_state.stock_symbol
                    stock_data = st.session_state.processed_df
                    index_data = st.session_state.index_df
                    
                    # æç¤ºç”¨æˆ·
                    st.write(f"æ‚¨å½“å‰åˆ†æçš„è‚¡ç¥¨({stock_symbol})æ˜¯å¦å±äº{selected_industry}è¡Œä¸š:")
                    
                    # æ£€æŸ¥å½“å‰è‚¡ç¥¨æ˜¯å¦å±äºæ‰€é€‰è¡Œä¸š
                    is_in_industry = False
                    for code in stock_codes:
                        if code.endswith(stock_symbol):
                            is_in_industry = True
                            break
                    
                    st.write("æ˜¯" if is_in_industry else "å¦")
                    
                    # è¡Œä¸šæŒ‡æ•°èµ°åŠ¿ (è¿™é‡Œä»…åšç¤ºä¾‹ï¼Œå®é™…éœ€è¦è·å–æ›´å¤šè¡Œä¸šè‚¡ç¥¨æ•°æ®)
                    st.write("å¦‚éœ€è·å–å®Œæ•´è¡Œä¸šæŒ‡æ•°æ•°æ®ï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šæ•°æ®æº")

# æœºå™¨å­¦ä¹ é¢„æµ‹æ ‡ç­¾é¡µ
def ml_prediction_tab():
    st.header("æœºå™¨å­¦ä¹ é¢„æµ‹")
    
    if 'processed_df' in st.session_state:
        # åˆ›å»ºä¸¤åˆ—
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("å›å½’é¢„æµ‹")
            
            # é€‰æ‹©å›å½’ç›®æ ‡
            regression_target = st.selectbox(
                "é€‰æ‹©å›å½’é¢„æµ‹ç›®æ ‡",
                ['Target_Regression_1d', 'Target_Regression_3d', 'Target_Regression_5d']
            )
            
            # é€‰æ‹©å›å½’æ¨¡å‹
            regression_model = st.selectbox(
                "é€‰æ‹©å›å½’æ¨¡å‹",
                ['linear_regression', 'decision_tree', 'random_forest', 'svm']
            )
            
            # è®­ç»ƒå›å½’æ¨¡å‹æŒ‰é’®
            if st.button("è®­ç»ƒå›å½’æ¨¡å‹"):
                with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
                    # åˆ›å»ºç‰¹å¾å’Œç›®æ ‡
                    X_train, X_test, y_train, y_test, scaler, feature_cols = create_features(
                        st.session_state.processed_df, regression_target
                    )
                    
                    # è®­ç»ƒæ¨¡å‹
                    model = train_model(X_train, y_train, regression_model)
                    
                    # é¢„æµ‹
                    y_pred = model.predict(X_test)
                    
                    # è®¡ç®—MSE
                    mse = mean_squared_error(y_test, y_pred)
                    rmse = np.sqrt(mse)
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.regression_results = {
                        'y_test': y_test,
                        'y_pred': y_pred,
                        'mse': mse,
                        'rmse': rmse,
                        'model': model,
                        'model_name': regression_model,
                        'target': regression_target
                    }
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.success(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå‡æ–¹è¯¯å·®(MSE): {mse:.6f}, å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse:.6f}")
                    
                    # å¯è§†åŒ–é¢„æµ‹ç»“æœ
                    fig = plot_prediction_results(y_test, y_pred, regression_model)
                    st.pyplot(fig)
                    
                    # ä½¿ç”¨å¤§æ¨¡å‹è§£è¯»å›å½’é¢„æµ‹ç»“æœ
                    st.subheader("AIè§£è¯»é¢„æµ‹ç»“æœ")
                    with st.spinner("æ­£åœ¨ç”ŸæˆAIåˆ†ææŠ¥å‘Š..."):
                        symbol = st.session_state.get('stock_symbol', 'UNKNOWN')
                        interpretation = interpret_prediction_with_llm(
                            symbol, 
                            y_pred, 
                            regression_model, 
                            f"RMSE: {rmse:.6f}"
                        )
                        st.info(interpretation)
                    
                    # ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“
                    symbol = st.session_state.get('stock_symbol', 'UNKNOWN')
                    save_prediction_to_db(
                        symbol=symbol,
                        model_name=regression_model,
                        prediction_date=datetime.now().strftime('%Y-%m-%d'),
                        predicted_value=float(y_pred[-1]),
                        actual_value=float(y_test[-1]) if len(y_test) > 0 else None,
                        accuracy=float(rmse),
                        model_params={"features": feature_cols}
                    )
        
        with col2:
            st.subheader("åˆ†ç±»é¢„æµ‹")
            
            # é€‰æ‹©åˆ†ç±»æ¨¡å‹
            classification_model = st.selectbox(
                "é€‰æ‹©åˆ†ç±»æ¨¡å‹",
                ['decision_tree_classifier', 'random_forest_classifier', 'svm_classifier']
            )
            
            # è®­ç»ƒåˆ†ç±»æ¨¡å‹æŒ‰é’®
            if st.button("è®­ç»ƒåˆ†ç±»æ¨¡å‹"):
                with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
                    # åˆ›å»ºç‰¹å¾å’Œç›®æ ‡
                    X_train, X_test, y_train, y_test, scaler, feature_cols = create_features(
                        st.session_state.processed_df, 'Target_Classification'
                    )
                    
                    # è®­ç»ƒæ¨¡å‹
                    model = train_model(X_train, y_train, classification_model)
                    
                    # é¢„æµ‹
                    y_pred = model.predict(X_test)
                    
                    # è®¡ç®—å‡†ç¡®ç‡
                    accuracy = accuracy_score(y_test, y_pred)
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.classification_results = {
                        'y_test': y_test,
                        'y_pred': y_pred,
                        'accuracy': accuracy,
                        'model': model,
                        'model_name': classification_model
                    }
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.success(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.4f}")
                    
                    # æ˜¾ç¤ºåˆ†ç±»æŠ¥å‘Š
                    report = classification_report(y_test, y_pred, output_dict=True)
                    report_df = pd.DataFrame(report).transpose()
                    st.write("åˆ†ç±»æŠ¥å‘Šï¼š")
                    st.dataframe(report_df)
                    
                    # å¯è§†åŒ–åˆ†ç±»ç»“æœ
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.plot(y_test, label='å®é™…å€¼', marker='o', linestyle='--')
                    ax.plot(y_pred, label='é¢„æµ‹å€¼', marker='x')
                    ax.set_title(f'{classification_model} åˆ†ç±»ç»“æœ')
                    ax.set_xlabel('æ ·æœ¬')
                    ax.set_ylabel('ç±»åˆ« (0:ä¸‹è·Œ, 1:ä¸Šæ¶¨)')
                    ax.legend()
                    ax.grid(True)
                    st.pyplot(fig)
                    
                    # ä½¿ç”¨å¤§æ¨¡å‹è§£è¯»é¢„æµ‹ç»“æœ
                    st.subheader("AIè§£è¯»é¢„æµ‹ç»“æœ")
                    with st.spinner("æ­£åœ¨ç”ŸæˆAIåˆ†ææŠ¥å‘Š..."):
                        symbol = st.session_state.get('stock_symbol', 'UNKNOWN')
                        interpretation = interpret_prediction_with_llm(
                            symbol, 
                            y_pred, 
                            classification_model, 
                            f"å‡†ç¡®ç‡: {accuracy:.4f}"
                        )
                        st.info(interpretation)
        
        # K-Meansèšç±»
        st.subheader("K-Meansèšç±»åˆ†æ")
        
        n_clusters = st.slider("é€‰æ‹©èšç±»æ•°é‡", 2, 5, 3)
        
        if st.button("æ‰§è¡Œèšç±»åˆ†æ"):
            with st.spinner("æ­£åœ¨æ‰§è¡Œèšç±»åˆ†æ..."):
                # æ‰§è¡Œèšç±»
                cluster_df, cluster_centers = cluster_stocks(
                    st.session_state.processed_df, n_clusters
                )
                
                st.session_state.cluster_df = cluster_df
                st.session_state.cluster_centers = cluster_centers
                
                # æ˜¾ç¤ºèšç±»ç»“æœ
                st.success(f"èšç±»åˆ†æå®Œæˆï¼Œå…± {n_clusters} ä¸ªèšç±»")
                
                # æ˜¾ç¤ºæ¯ä¸ªèšç±»çš„æ ·æœ¬æ•°
                cluster_counts = cluster_df['Cluster'].value_counts().sort_index()
                st.write("å„èšç±»æ ·æœ¬æ•°ï¼š")
                st.bar_chart(cluster_counts)
                
                # å¯è§†åŒ–èšç±»ç»“æœ
                fig = plot_clusters(cluster_df, 'Daily_Return', 'Volatility_5d')
                st.pyplot(fig)
                
                # åˆ†ææ¯ä¸ªèšç±»çš„ç‰¹å¾
                st.write("å„èšç±»ç‰¹å¾å‡å€¼ï¼š")
                cluster_means = cluster_df.groupby('Cluster').mean()
                st.dataframe(cluster_means[['Daily_Return', 'Volatility_5d', 'RSI']])
    else:
        st.info("è¯·å…ˆåœ¨æ•°æ®åˆ†ææ ‡ç­¾é¡µä¸­å¤„ç†è‚¡ç¥¨æ•°æ®")

# å¯è§†åŒ–å±•ç¤ºæ ‡ç­¾é¡µ
def visualization_tab():
    st.header("å¯è§†åŒ–å±•ç¤º")
    
    # è‚¡ç¥¨æ•°æ®å¯è§†åŒ–
    if 'processed_df' in st.session_state:
        st.subheader("è‚¡ç¥¨æ•°æ®å¯è§†åŒ–")
        
        viz_option = st.selectbox(
            "é€‰æ‹©å¯è§†åŒ–ç±»å‹",
            ['Kçº¿å›¾', 'ä»·æ ¼èµ°åŠ¿å›¾', 'æŠ€æœ¯æŒ‡æ ‡', 'ç›¸å…³æ€§çƒ­åŠ›å›¾']
        )
        
        if viz_option == 'Kçº¿å›¾':
            fig = plot_candlestick(st.session_state.processed_df)
            st.pyplot(fig)
        
        elif viz_option == 'ä»·æ ¼èµ°åŠ¿å›¾':
            fig = plot_stock_price(st.session_state.processed_df)
            st.pyplot(fig)
        
        elif viz_option == 'æŠ€æœ¯æŒ‡æ ‡':
            fig = plot_technical_indicators(st.session_state.processed_df)
            st.pyplot(fig)
        
        elif viz_option == 'ç›¸å…³æ€§çƒ­åŠ›å›¾':
            fig = plot_correlation_heatmap(st.session_state.processed_df)
            st.pyplot(fig)
    
    # é¢„æµ‹ç»“æœå¯è§†åŒ–
    if 'regression_results' in st.session_state or 'classification_results' in st.session_state:
        st.subheader("é¢„æµ‹ç»“æœå¯è§†åŒ–")
        
        pred_viz_option = st.radio(
            "é€‰æ‹©é¢„æµ‹ç»“æœç±»å‹",
            ['å›å½’é¢„æµ‹', 'åˆ†ç±»é¢„æµ‹'],
            horizontal=True
        )
        
        if pred_viz_option == 'å›å½’é¢„æµ‹' and 'regression_results' in st.session_state:
            results = st.session_state.regression_results
            fig = plot_prediction_results(results['y_test'], results['y_pred'], results['model_name'])
            st.pyplot(fig)
            
            st.metric("å‡æ–¹æ ¹è¯¯å·® (RMSE)", f"{results['rmse']:.6f}")
        
        elif pred_viz_option == 'åˆ†ç±»é¢„æµ‹' and 'classification_results' in st.session_state:
            results = st.session_state.classification_results
            
            # æ˜¾ç¤ºæ··æ·†çŸ©é˜µ
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(results['y_test'], results['y_pred'])
            
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues')
            ax.set_xlabel('é¢„æµ‹ç±»åˆ«')
            ax.set_ylabel('å®é™…ç±»åˆ«')
            ax.set_title('æ··æ·†çŸ©é˜µ')
            ax.set_xticklabels(['ä¸‹è·Œ', 'ä¸Šæ¶¨'])
            ax.set_yticklabels(['ä¸‹è·Œ', 'ä¸Šæ¶¨'])
            st.pyplot(fig)
            
            st.metric("å‡†ç¡®ç‡", f"{results['accuracy']:.4f}")
    
    # èšç±»ç»“æœå¯è§†åŒ–
    if 'cluster_df' in st.session_state:
        st.subheader("èšç±»ç»“æœå¯è§†åŒ–")
        
        # é€‰æ‹©è¦åœ¨æ•£ç‚¹å›¾ä¸­æ˜¾ç¤ºçš„ç‰¹å¾
        col1, col2 = st.columns(2)
        with col1:
            x_feature = st.selectbox("Xè½´ç‰¹å¾", ['Daily_Return', 'Volatility_5d', 'RSI', 'close'])
        with col2:
            y_feature = st.selectbox("Yè½´ç‰¹å¾", ['Volatility_5d', 'Daily_Return', 'RSI', 'close'])
        
        fig = plot_clusters(st.session_state.cluster_df, x_feature, y_feature)
        st.pyplot(fig)
        
        # æ¯ä¸ªèšç±»çš„ç‰¹å¾åˆ†å¸ƒ
        cluster_stats = st.session_state.cluster_df.groupby('Cluster').agg({
            'Daily_Return': ['mean', 'std'],
            'Volatility_5d': ['mean', 'std'],
            'RSI': ['mean', 'std'] if 'RSI' in st.session_state.cluster_df.columns else None
        }).dropna(axis=1)
        
        st.write("èšç±»ç»Ÿè®¡ä¿¡æ¯ï¼š")
        st.dataframe(cluster_stats)
    
    # æ–°é—»æ•°æ®å¯è§†åŒ–
    if 'news_df' in st.session_state:
        st.subheader("æ–°é—»æ•°æ®å¯è§†åŒ–")
        
        news_viz_option = st.radio(
            "é€‰æ‹©æ–°é—»å¯è§†åŒ–ç±»å‹",
            ['æƒ…æ„Ÿåˆ†æ', 'å…³é”®è¯è¯äº‘'],
            horizontal=True
        )
        
        if news_viz_option == 'æƒ…æ„Ÿåˆ†æ':
            fig = plot_news_sentiment(st.session_state.news_df)
            if fig:
                st.pyplot(fig)
            else:
                st.info("æ— æ³•ç”Ÿæˆæƒ…æ„Ÿåˆ†æå›¾ï¼Œè¯·ç¡®ä¿æ–°é—»æ•°æ®åŒ…å«æƒ…æ„Ÿåˆ†æ•°å’Œæ—¥æœŸ")
        
        elif news_viz_option == 'å…³é”®è¯è¯äº‘':
            fig = generate_news_wordcloud(st.session_state.news_df)
            if fig:
                st.pyplot(fig)
            else:
                st.info("æ— æ³•ç”Ÿæˆè¯äº‘ï¼Œè¯·ç¡®ä¿æ–°é—»æ•°æ®åŒ…å«å…³é”®è¯æˆ–æ ‡é¢˜")
    
    # æŒ‡æ•°å¯è§†åŒ–
    if 'index_df' in st.session_state:
        st.subheader("æŒ‡æ•°æ•°æ®å¯è§†åŒ–")
        
        index_df = st.session_state.index_df
        index_name = st.session_state.index_name
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        if 'MA5' not in index_df.columns:
            index_df['MA5'] = index_df['close'].rolling(window=5).mean()
            index_df['MA20'] = index_df['close'].rolling(window=20).mean()
            index_df['MA60'] = index_df['close'].rolling(window=60).mean()
        
        # ç»˜åˆ¶æŒ‡æ•°èµ°åŠ¿å›¾
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(index_df.index, index_df['close'], label='æ”¶ç›˜ä»·')
        ax.plot(index_df.index, index_df['MA5'], label='5æ—¥å‡çº¿')
        ax.plot(index_df.index, index_df['MA20'], label='20æ—¥å‡çº¿')
        ax.plot(index_df.index, index_df['MA60'], label='60æ—¥å‡çº¿')
        ax.set_title(f'{index_name}èµ°åŠ¿å›¾')
        ax.set_xlabel('æ—¥æœŸ')
        ax.set_ylabel('æŒ‡æ•°ç‚¹ä½')
        ax.legend()
        ax.grid(True)
        plt.xticks(rotation=45)
        plt.tight_layout()
        st.pyplot(fig)
        
        # ç»˜åˆ¶æŒ‡æ•°Kçº¿å›¾
        # é‡å‘½ååˆ—ä»¥åŒ¹é…mplfinanceè¦æ±‚
        index_plot_df = index_df.copy()
        index_plot_df = index_plot_df.rename(columns={
            'open': 'Open',
            'high': 'High',
            'low': 'Low',
            'close': 'Close',
            'volume': 'Volume'
        })
        index_plot_df.index.name = 'Date'
        
        fig, axlist = mpf.plot(index_plot_df, type='candle', volume=True, 
                              title=f'{index_name} Kçº¿å›¾',
                              ylabel='æŒ‡æ•°ç‚¹ä½',
                              ylabel_lower='æˆäº¤é‡',
                              style='charles',
                              returnfig=True,
                              figsize=(10, 8))
        st.pyplot(fig)

# å¯¼å‡ºç»“æœæ ‡ç­¾é¡µ
def export_tab():
    st.header("å¯¼å‡ºç»“æœ")
    
    # é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®
    export_option = st.selectbox(
        "é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®",
        ['è‚¡ç¥¨åŸå§‹æ•°æ®', 'å¤„ç†åçš„è‚¡ç¥¨æ•°æ®', 'é¢„æµ‹ç»“æœ', 'æ–°é—»æ•°æ®', 'æŒ‡æ•°æ•°æ®', 'è´¢åŠ¡æ•°æ®']
    )
    
    # é€‰æ‹©å¯¼å‡ºæ ¼å¼
    export_format = st.radio(
        "é€‰æ‹©å¯¼å‡ºæ ¼å¼",
        ['CSV', 'Excel'],
        horizontal=True
    )
    
    if st.button("å¯¼å‡ºæ•°æ®"):
        if export_option == 'è‚¡ç¥¨åŸå§‹æ•°æ®' and 'stock_df' in st.session_state:
            if export_format == 'CSV':
                st.markdown(get_table_download_link(
                    st.session_state.stock_df, 
                    "stock_data.csv", 
                    "ä¸‹è½½CSVæ–‡ä»¶"
                ), unsafe_allow_html=True)
            else:
                st.markdown(export_to_excel(
                    st.session_state.stock_df, 
                    "stock_data.xlsx"
                ), unsafe_allow_html=True)
                
        elif export_option == 'å¤„ç†åçš„è‚¡ç¥¨æ•°æ®' and 'processed_df' in st.session_state:
            if export_format == 'CSV':
                st.markdown(get_table_download_link(
                    st.session_state.processed_df, 
                    "processed_stock_data.csv", 
                    "ä¸‹è½½CSVæ–‡ä»¶"
                ), unsafe_allow_html=True)
            else:
                st.markdown(export_to_excel(
                    st.session_state.processed_df, 
                    "processed_stock_data.xlsx"
                ), unsafe_allow_html=True)
                
        elif export_option == 'é¢„æµ‹ç»“æœ':
            if 'regression_results' in st.session_state:
                results = st.session_state.regression_results
                results_df = pd.DataFrame({
                    'actual': results['y_test'],
                    'predicted': results['y_pred']
                })
                
                if export_format == 'CSV':
                    st.markdown(get_table_download_link(
                        results_df, 
                        "prediction_results.csv", 
                        "ä¸‹è½½CSVæ–‡ä»¶"
                    ), unsafe_allow_html=True)
                else:
                    st.markdown(export_to_excel(
                        results_df, 
                        "prediction_results.xlsx"
                    ), unsafe_allow_html=True)
            else:
                st.warning("æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹ç»“æœ")
                
        elif export_option == 'æ–°é—»æ•°æ®' and 'news_df' in st.session_state:
            if export_format == 'CSV':
                st.markdown(get_table_download_link(
                    st.session_state.news_df, 
                    "news_data.csv", 
                    "ä¸‹è½½CSVæ–‡ä»¶"
                ), unsafe_allow_html=True)
            else:
                st.markdown(export_to_excel(
                    st.session_state.news_df, 
                    "news_data.xlsx"
                ), unsafe_allow_html=True)
        
        elif export_option == 'æŒ‡æ•°æ•°æ®' and 'index_df' in st.session_state:
            if export_format == 'CSV':
                st.markdown(get_table_download_link(
                    st.session_state.index_df, 
                    "index_data.csv", 
                    "ä¸‹è½½CSVæ–‡ä»¶"
                ), unsafe_allow_html=True)
            else:
                st.markdown(export_to_excel(
                    st.session_state.index_df, 
                    "index_data.xlsx"
                ), unsafe_allow_html=True)
        
        elif export_option == 'è´¢åŠ¡æ•°æ®' and 'financial_data' in st.session_state:
            financial_data = st.session_state.financial_data
            
            # é€‰æ‹©è¦å¯¼å‡ºçš„è´¢åŠ¡æŠ¥è¡¨ç±»å‹
            financial_type = st.selectbox(
                "é€‰æ‹©è´¢åŠ¡æŠ¥è¡¨ç±»å‹",
                ['performance', 'profit', 'balance', 'cash_flow']
            )
            
            if financial_data[financial_type] is not None and not financial_data[financial_type].empty:
                if export_format == 'CSV':
                    st.markdown(get_table_download_link(
                        financial_data[financial_type], 
                        f"{financial_type}_data.csv", 
                        "ä¸‹è½½CSVæ–‡ä»¶"
                    ), unsafe_allow_html=True)
                else:
                    st.markdown(export_to_excel(
                        financial_data[financial_type], 
                        f"{financial_type}_data.xlsx"
                    ), unsafe_allow_html=True)
            else:
                st.warning(f"æ²¡æœ‰å¯ç”¨çš„{financial_type}è´¢åŠ¡æ•°æ®")
                
        else:
            st.warning("æ²¡æœ‰å¯ç”¨çš„æ•°æ®")
    
    # æå–æ•°æ®åº“ä¸­çš„é¢„æµ‹ç»“æœ
    st.subheader("ä»æ•°æ®åº“è·å–å†å²é¢„æµ‹")
    
    if st.button("æŸ¥è¯¢å†å²é¢„æµ‹"):
        try:
            conn = create_connection()
            cursor = conn.cursor()
            
            cursor.execute("""
            SELECT symbol, model_name, prediction_date, predicted_value, actual_value, accuracy
            FROM prediction_results
            ORDER BY prediction_date DESC
            LIMIT 50
            """)
            
            result = cursor.fetchall()
            
            if result:
                predictions_df = pd.DataFrame(result, columns=[
                    'è‚¡ç¥¨ä»£ç ', 'æ¨¡å‹åç§°', 'é¢„æµ‹æ—¥æœŸ', 'é¢„æµ‹å€¼', 'å®é™…å€¼', 'å‡†ç¡®ç‡'
                ])
                
                st.write("å†å²é¢„æµ‹ç»“æœï¼š")
                st.dataframe(predictions_df)
                
                if export_format == 'CSV':
                    st.markdown(get_table_download_link(
                        predictions_df, 
                        "historical_predictions.csv", 
                        "ä¸‹è½½å†å²é¢„æµ‹æ•°æ®"
                    ), unsafe_allow_html=True)
                else:
                    st.markdown(export_to_excel(
                        predictions_df, 
                        "historical_predictions.xlsx"
                    ), unsafe_allow_html=True)
            else:
                st.info("æ•°æ®åº“ä¸­æ²¡æœ‰å†å²é¢„æµ‹æ•°æ®")
            
            cursor.close()
            conn.close()
            
        except Exception as e:
            st.error(f"æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")
    
    # æ•°æ®åº“è¡¨æŸ¥è¯¢
    st.subheader("æ•°æ®åº“è¡¨æŸ¥è¯¢")
    
    table_name = st.selectbox(
        "é€‰æ‹©è¦æŸ¥è¯¢çš„è¡¨",
        ['stock_data', 'news_data', 'prediction_results', 'index_data', 'financial_data']
    )
    
    limit = st.slider("é™åˆ¶è¿”å›è®°å½•æ•°", 10, 1000, 100)
    
    if st.button("æŸ¥è¯¢æ•°æ®"):
        try:
            conn = create_connection()
            cursor = conn.cursor()
            
            cursor.execute(f"SELECT * FROM {table_name} LIMIT {limit}")
            
            result = cursor.fetchall()
            
            if result:
                # è·å–åˆ—å
                cursor.execute(f"SHOW COLUMNS FROM {table_name}")
                columns = [column[0] for column in cursor.fetchall()]
                
                # åˆ›å»ºDataFrame
                df = pd.DataFrame(result, columns=columns)
                
                st.write(f"{table_name} è¡¨æ•°æ®:")
                st.dataframe(df)
                
                if export_format == 'CSV':
                    st.markdown(get_table_download_link(
                        df, 
                        f"{table_name}_query.csv", 
                        "ä¸‹è½½æŸ¥è¯¢ç»“æœ"
                    ), unsafe_allow_html=True)
                else:
                    st.markdown(export_to_excel(
                        df, 
                        f"{table_name}_query.xlsx"
                    ), unsafe_allow_html=True)
            else:
                st.info(f"{table_name} è¡¨ä¸­æ²¡æœ‰æ•°æ®")
            
            cursor.close()
            conn.close()
            
        except Exception as e:
            st.error(f"æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")

# ä¸»å‡½æ•°
def main():
    st.title("é‡‘èæ•°æ®åˆ†æä¸é¢„æµ‹ç³»ç»Ÿ")
    
    # ä¾§è¾¹æ  - ç³»ç»Ÿé…ç½®
    st.sidebar.header("ç³»ç»Ÿé…ç½®")
    
    # åˆå§‹åŒ–æ•°æ®åº“æŒ‰é’®
    if st.sidebar.button("åˆå§‹åŒ–æ•°æ®åº“"):
        init_database()
    
    # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
    st.sidebar.subheader("ç³»ç»Ÿä¿¡æ¯")
    st.sidebar.info("""
    ç‰ˆæœ¬: 1.0.0
    æ•°æ®æº: BaoStock
    æ”¯æŒ: Aè‚¡å¸‚åœº
    åŠŸèƒ½: è‚¡ç¥¨æ•°æ®åˆ†æã€æŠ€æœ¯æŒ‡æ ‡ã€æœºå™¨å­¦ä¹ é¢„æµ‹
    """)
    
    # æ˜¾ç¤ºå½“å‰æ—¥æœŸ
    st.sidebar.subheader("å½“å‰æ—¥æœŸ")
    st.sidebar.write(datetime.now().strftime('%Y-%m-%d'))
    
    # æ·»åŠ æ•°æ®æ¸…ç†é€‰é¡¹
    st.sidebar.subheader("æ•°æ®ç®¡ç†")
    if st.sidebar.button("æ¸…é™¤æ‰€æœ‰ä¼šè¯æ•°æ®"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.sidebar.success("å·²æ¸…é™¤æ‰€æœ‰ä¼šè¯æ•°æ®")
    
    # ä¸»ç•Œé¢æ ‡ç­¾é¡µ
    tabs = st.tabs(["æ•°æ®è·å–", "æ•°æ®åˆ†æ", "æœºå™¨å­¦ä¹ é¢„æµ‹", "å¯è§†åŒ–å±•ç¤º", "å¯¼å‡ºç»“æœ"])
    
    # æ•°æ®è·å–æ ‡ç­¾é¡µ
    with tabs[0]:
        data_acquisition_tab()
    
    # æ•°æ®åˆ†ææ ‡ç­¾é¡µ
    with tabs[1]:
        data_analysis_tab()
    
    # æœºå™¨å­¦ä¹ é¢„æµ‹æ ‡ç­¾é¡µ
    with tabs[2]:
        ml_prediction_tab()
    
    # å¯è§†åŒ–å±•ç¤ºæ ‡ç­¾é¡µ
    with tabs[3]:
        visualization_tab()
    
    # å¯¼å‡ºç»“æœæ ‡ç­¾é¡µ
    with tabs[4]:
        export_tab()

if __name__ == "__main__":
    main()